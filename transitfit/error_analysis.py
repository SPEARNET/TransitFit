"""
This python file takes output_parameters folder as input and provides 
asymmetric errors using the distribution of samples. 
"""
import glob
import pickle
import numpy as np
import pandas as pd


def get_quantiles_on_best_val(samples, weights, best_val):
    """Generates lower and upper limit of errors for the best values.
    Sorts the samples and corresponding weights. 
    Gets value of samples such that they encompass 68.27% of the samples
    by weight on both sides of the best value.

    Args:
        samples (array): the sampled values for the parameter from dynesty
        weights (array): weights of the samples
        best_val (float): best value among the samples

    Returns:
        tuple: the lower and upper error on the best value.
    """

    weights = weights/np.sum(weights)
    sorter_sample = np.argsort(samples)

    sorted_weights = weights[sorter_sample]
    sorted_samples = samples[sorter_sample]

    best_val_idx = np.argmin(np.abs(sorted_samples-float(best_val)))

    total_sum = 0
    for i in range(best_val_idx, len(sorted_weights)):
        total_sum += sorted_weights[i]
        if total_sum >= .6827*np.sum(sorted_weights[best_val_idx:]):
            upper_error = sorted_samples[i]-best_val
            break

    total_sum = 0
    for i in range(best_val_idx, 0, -1):
        total_sum += sorted_weights[i]
        if total_sum >= .6827*np.sum(sorted_weights[:best_val_idx]):
            lower_error = sorted_samples[i]-best_val
            break

    return lower_error, upper_error

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#


def make_dict(val_dict, key, vals):
    """makes dictionary using the given values. if the key already 
    exists, then the values get appended. 

    Args:
        val_dict (dict): the dictionary where the values are to be added
        key (str): the key of the value
        vals (array): the values to be added
    """
    if key in val_dict:
        val_dict[key] = np.ndarray.flatten(np.append(val_dict[key], vals))
    else:
        val_dict[key] = np.ndarray.flatten(vals)


class ErrorLimits:
    """
    Initializes the error limit analysis.
    """

    def __init__(self, output_parmeters):
        """

        Args:
            output_parmeters (str): path of the output_parameters folder
                                    generated by TransitFit
        """
        # The path to the output_parameters folder from the TransitFit output.
        self.OUTPUT_PARAMETERS_FOLDER = output_parmeters

        # This will be the name of the output file
        self.MODIFIED_SUMMARY_OUTPUT = 'modifed_output.csv'

        # Searching for all the .pkl files
        self.files_pkl = glob.glob(
            self.OUTPUT_PARAMETERS_FOLDER+'/quicksaves/*results.pkl')
        self.files_pkl.sort()

        # Searching for all the .csv files
        self.output_csvs = glob.glob(
            self.OUTPUT_PARAMETERS_FOLDER+'/quicksaves/*output.csv')
        self.output_csvs.sort()

        # In folded mode, there is additional filter-dependent folder inside
        # output_parameters, checking if that is the case.
        self.folded_mode_csv = glob.glob(
            self.OUTPUT_PARAMETERS_FOLDER+'/*/quicksaves/*output.csv')

        if len(self.folded_mode_csv) != 0:
            print('Folded mode detected.')
            self.FOLDED_MODE = True
            self.folded_mode_pkl = glob.glob(
                self.OUTPUT_PARAMETERS_FOLDER+'/*/quicksaves/*results.pkl')
            self.folded_mode_pkl.sort()
            self.folded_mode_csv.sort()

        else:
            self.FOLDED_MODE = False
            self.folded_params = []

        # The list of required parameters to analyze
        self.required_params = ['P', 't0', 'a/r*', 'inc', 'rp/r*']

    def get_errors(self):

        # Initalising values dictionary and filters list.
        values = {}
        filters = []

        # Getting the values of 'P' and 't0' in case of folded mode.
        if self.FOLDED_MODE:
            self.folded_params = self.required_params[:2]
            self.required_params = self.required_params[2:]
            for i, file in enumerate(self.folded_mode_pkl):
                with open(file, 'rb') as handle:
                    result = pickle.load(handle)

                df_csv = pd.read_csv(self.folded_mode_csv[i])

                for i, param in enumerate(self.folded_params):
                    selected_df = df_csv.loc[df_csv['Parameter'] == param]
                    index = selected_df.index

                    make_dict(values, param, result.samples[:, index])
                    make_dict(values, param+'_weights', result.weights)

        for i, file in enumerate(self.files_pkl):
            with open(file, 'rb') as handle:
                result = pickle.load(handle)

            df_csv = pd.read_csv(self.output_csvs[i])

            for i, param in enumerate(self.required_params):
                selected_df = df_csv.loc[df_csv['Parameter'] == param]
                index = selected_df.index
                if param in {'inc', 'rp/r*'}:
                    # To account for a/AU parameter present in the
                    # summary_output files.
                    index = index-1

                if len(selected_df) > 1:
                    batch_filters = selected_df['Filter'].to_list()
                    filters += batch_filters
                    for i, f in enumerate(batch_filters):
                        make_dict(values, param+'_'+f,
                                  result.samples[:, index[i]])
                        make_dict(values, param+'_'+f +
                                  '_weights', result.weights)
                        i = 2*i  # q0 and q1 are saved as pairs in the .pkl files
                        make_dict(values, 'q0'+'_'+f,
                                  result.samples[:, index[-1]+1+i])
                        make_dict(values, 'q1'+'_'+f,
                                  result.samples[:, index[-1]+1+i+1])

                        make_dict(values, 'q0'+'_'+f +
                                  '_weights', result.weights)
                        make_dict(values, 'q1'+'_'+f +
                                  '_weights', result.weights)

                else:

                    make_dict(values, param, result.samples[:, index])
                    make_dict(values, param+'_weights', result.weights)

                    if param == 'rp/r*':  # Folded mode
                        make_dict(values, 'q0', result.samples[:, index+1])
                        make_dict(values, 'q1', result.samples[:, index+2])

                        make_dict(values, 'q0'+'_weights', result.weights)
                        make_dict(values, 'q1'+'_weights', result.weights)

        self.required_params = self.folded_params + \
            self.required_params+['q0', 'q1']
        filters = list(set(filters))
        filters.sort()

        summary_output = glob.glob(
            self.OUTPUT_PARAMETERS_FOLDER+'/*summary_output.csv')
        df_so = pd.read_csv(summary_output[0])

        # Getting the best_values from the summary_output.csv file
        for p in self.required_params:
            selected_df = df_so.loc[df_so['Parameter'] == p]
            if len(selected_df) == 1:
                values[p+'_best'] = float(selected_df['Best'])

            else:
                batch_filters = selected_df['Filter']
                bestvals = selected_df['Best'].to_numpy(dtype=float)
                for i, f in enumerate(batch_filters):
                    values[p+'_'+str(f)+'_best'] = float(bestvals[i])

        # Generating the output
        with open(self.OUTPUT_PARAMETERS_FOLDER+'/'+self.MODIFIED_SUMMARY_OUTPUT, 'w') as mso:
            mso.write('Parameter, Filter, Best, Lower_error, Upper_error\n')
            for param in self.required_params:
                if param in {'rp/r*', 'q0', 'q1'} and len(filters) > 0:
                    for fil in filters:
                        param_ = param+'_'+fil
                        errs = get_quantiles_on_best_val(
                            samples=values[param_], weights=values[param_+'_weights'], best_val=values[param_+'_best'])
                        # (model.mean)
                        mso.write(
                            f"{param},{fil},{values[param_+'_best']},{errs[0]},{errs[1]}\n")

                else:
                    errs = get_quantiles_on_best_val(
                        samples=values[param], weights=values[param+'_weights'], best_val=values[param+'_best'])
                    mso.write(
                        f"{param},-,{values[param+'_best']},{errs[0]},{errs[1]}\n")

        print(
            f"Saved results in {self.OUTPUT_PARAMETERS_FOLDER+'/'+self.MODIFIED_SUMMARY_OUTPUT}")
